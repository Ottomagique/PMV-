import streamlit as st
import pandas as pd
import numpy as np
import io
import matplotlib.pyplot as plt
from itertools import combinations
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import Pipeline
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import math

# üìå Configuration de la page
st.set_page_config(
    page_title="Analyse IPMVP Simplifi√©e",
    page_icon="üìä",
    layout="wide"
)

# üîπ Appliquer le CSS (Uniquement pour am√©liorer le design)
st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Manrope:wght@400;700;800&display=swap');

    html, body, [class*="st-"] {
        font-family: 'Manrope', sans-serif;
        color: #0C1D2D;
    }

    h1, h2, h3 {
        font-weight: 800;
        color: #00485F;
    }

    h4, h5, h6 {
        font-weight: 700;
        color: #00485F;
    }

    .stButton>button {
        background-color: #6DBABC;
        color: white;
        border-radius: 8px;
        padding: 12px 18px;
        font-size: 16px;
        font-weight: bold;
        border: none;
        transition: all 0.3s ease-in-out;
    }

    .stButton>button:hover {
        background-color: #96B91D;
        color: white;
        transform: scale(1.05);
    }

    .stSidebar {
        background-color: #E7DDD9;
        padding: 20px;
        border-radius: 10px;
    }

    input, select, textarea {
        background-color: #E7DDD9 !important;
        border-radius: 5px;
        border: 1px solid #00485F;
    }

    .block-container {
        padding: 2rem;
        border-radius: 10px;
        background-color: #E7DDD9;
    }

    .stDataFrame {
        border: 1px solid #0C1D2D;
        border-radius: 10px;
    }

    .metrics-card {
        background-color: #E7DDD9;
        border-radius: 10px;
        padding: 15px;
        margin: 10px 0;
        box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        border: 1px solid #00485F;
    }
    
    .equation-box {
        background-color: #E7DDD9;
        border-left: 4px solid #6DBABC;
        padding: 15px;
        margin: 15px 0;
        border-radius: 0 10px 10px 0;
        font-family: monospace;
        border: 1px solid #00485F;
    }
    
    .conformity-good {
        color: #96B91D;
        font-weight: bold;
    }
    
    .conformity-medium {
        color: #f39c12;
        font-weight: bold;
    }
    
    .conformity-bad {
        color: #e74c3c;
        font-weight: bold;
    }
    
    .footer-credit {
        text-align: center;
        margin-top: 30px;
        padding: 15px;
        background-color: #00485F;
        color: white;
        border-radius: 10px;
        font-size: 14px;
    }
    
    .instruction-card {
        background-color: #E7DDD9;
        border-left: 4px solid #96B91D;
        padding: 15px;
        margin: 15px 0;
        border-radius: 0 10px 10px 0;
    }
    
    .table-header {
        background-color: #00485F;
        color: white;
    }
    
    /* Style des info-bulles */
    .tooltip {
        position: relative;
        display: inline-block;
        cursor: help;
        color: #00485F;
        font-size: 14px;
        margin-left: 4px;
    }
    
    .tooltip .tooltiptext {
        visibility: hidden;
        width: 250px;
        background-color: #00485F;
        color: white;
        text-align: left;
        border-radius: 6px;
        padding: 10px;
        position: absolute;
        z-index: 1;
        bottom: 125%;
        left: 50%;
        margin-left: -125px;
        opacity: 0;
        transition: opacity 0.3s;
        font-size: 13px;
        line-height: 1.4;
        box-shadow: 0 3px 10px rgba(0,0,0,0.2);
    }
    
    .tooltip .tooltiptext::after {
        content: "";
        position: absolute;
        top: 100%;
        left: 50%;
        margin-left: -5px;
        border-width: 5px;
        border-style: solid;
        border-color: #00485F transparent transparent transparent;
    }
    
    .tooltip:hover .tooltiptext {
        visibility: visible;
        opacity: 1;
    }
    
    .model-badge {
        display: inline-block;
        background-color: #6DBABC;
        color: white;
        padding: 4px 8px;
        border-radius: 4px;
        font-size: 12px;
        font-weight: bold;
        margin-left: 8px;
    }

    </style>
    """, unsafe_allow_html=True)

# üìå **Description de l'application**
st.title("üìä Calcul IPMVP")
st.markdown("""
Bienvenue sur **l'Analyse IPMVP Professionnelle** üîç !  
Cette application vous permet d'analyser **vos donn√©es de consommation √©nerg√©tique** et de trouver le meilleur mod√®le d'ajustement bas√© sur plusieurs variables explicatives selon la m√©thodologie IPMVP.
""")

st.markdown("""
<div class="instruction-card">
<h3>üõ†Ô∏è Guide d'utilisation</h3>
<ol>
    <li><strong>Pr√©paration du fichier Excel</strong> : Assurez-vous que votre fichier contient une colonne de dates, une colonne de consommation et des variables explicatives potentielles (degr√©s-jours, occupation, production, etc.)</li>
    <li><strong>Import du fichier</strong> : Utilisez le bouton d'import pour charger votre fichier Excel (.xlsx ou .xls)</li>
    <li><strong>S√©lection des donn√©es</strong> : Dans le panneau lat√©ral, s√©lectionnez :
        <ul>
            <li>La colonne de date</li>
            <li>La colonne de consommation √©nerg√©tique</li>
            <li>Les variables explicatives potentielles (Ensoleillement, DJU, etc.)</li>
        </ul>
    </li>
    <li><strong>Choix de la p√©riode d'analyse</strong> : Deux options sont disponibles :
        <ul>
            <li>Recherche automatique : l'application trouve la meilleure p√©riode de 12 mois dans vos donn√©es</li>
            <li>S√©lection manuelle : choisissez vous-m√™me la p√©riode d'analyse en s√©lectionnant les dates de d√©but et de fin</li>
        </ul>
    </li>
    <li><strong>Type de mod√®le</strong> : Par d√©faut, l'application teste tous les types de mod√®les (lin√©aire, Ridge, Lasso, polynomiale) et s√©lectionne le meilleur, ou vous pouvez choisir un type sp√©cifique</li>
    <li><strong>Configuration de l'analyse</strong> : Choisissez le nombre maximum de variables √† combiner (1 √† 4)</li>
    <li><strong>Lancement</strong> : Cliquez sur "Lancer le calcul" pour obtenir le meilleur mod√®le d'ajustement</li>
    <li><strong>Analyse des r√©sultats</strong> : Examinez les m√©triques (R¬≤, CV, biais), l'√©quation d'ajustement et les visualisations g√©n√©r√©es</li>
</ol>
</div>
""", unsafe_allow_html=True)

# üìÇ **Import du fichier et lancement du calcul**
col1, col2 = st.columns([3, 1])  # Mise en page : Import √† gauche, bouton √† droite

with col1:
    uploaded_file = st.file_uploader("üìÇ Importer un fichier Excel", type=["xlsx", "xls"])

with col2:
    lancer_calcul = st.button("üöÄ Lancer le calcul", use_container_width=True)

# üìÇ **S√©lection des donn√©es (toujours visible m√™me sans fichier import√©)**
st.sidebar.header("üîç S√©lection des donn√©es")

df = None  # Initialisation pour √©viter des erreurs

if uploaded_file:
    df = pd.read_excel(uploaded_file)  # Chargement du fichier

# **D√©finition des colonnes pour la s√©lection AVANT import**
date_col = st.sidebar.selectbox("üìÖ Nom de la donn√©e date", df.columns if df is not None else [""])
conso_col = st.sidebar.selectbox("‚ö° Nom de la donn√©e consommation", df.columns if df is not None else [""])

# **Option pour rechercher automatiquement la meilleure p√©riode de 12 mois ou choisir une p√©riode**
period_choice = st.sidebar.radio(
    "üìÖ S√©lection de la p√©riode d'analyse",
    ["Rechercher automatiquement la meilleure p√©riode de 12 mois", "S√©lectionner manuellement une p√©riode sp√©cifique"]
)

# Variables pour stocker les informations de la meilleure p√©riode
best_period_start = None
best_period_end = None
best_period_name = None
best_period_r2 = -1

# Option de s√©lection manuelle de p√©riode
if period_choice == "S√©lectionner manuellement une p√©riode sp√©cifique" and df is not None and date_col in df.columns:
    # Convertir la colonne de date si elle ne l'est pas d√©j√†
    if not pd.api.types.is_datetime64_any_dtype(df[date_col]):
        try:
            df[date_col] = pd.to_datetime(df[date_col])
        except:
            st.sidebar.warning("‚ö†Ô∏è La colonne de date n'a pas pu √™tre convertie. Assurez-vous qu'elle contient des dates valides.")
    
    if pd.api.types.is_datetime64_any_dtype(df[date_col]):
        # Obtenir les dates minimales et maximales
        min_date = df[date_col].min().date()
        max_date = df[date_col].max().date()
        
        # S√©lection de la date de d√©but et de fin
        col1, col2 = st.sidebar.columns(2)
        with col1:
            start_date = st.date_input("Date de d√©but", 
                                       value=min_date,
                                       min_value=min_date, 
                                       max_value=max_date)
        with col2:
            # Calcul de la date par d√©faut (12 mois apr√®s la date de d√©but si possible)
            default_end = min(max_date, (pd.to_datetime(start_date) + pd.DateOffset(months=11)).date())
            end_date = st.date_input("Date de fin", 
                                     value=default_end,
                                     min_value=start_date, 
                                     max_value=max_date)
        
        # Calculer la diff√©rence en mois
        months_diff = (end_date.year - start_date.year) * 12 + (end_date.month - start_date.month) + 1
        
        # Afficher des informations sur la p√©riode s√©lectionn√©e
        st.sidebar.info(f"P√©riode s√©lectionn√©e: {start_date.strftime('%d/%m/%Y')} - {end_date.strftime('%d/%m/%Y')} ({months_diff} mois)")
        
        # Recommandation pour 12 mois
        if months_diff != 12:
            if months_diff < 12:
                st.sidebar.warning(f"‚ö†Ô∏è La p√©riode s√©lectionn√©e est de {months_diff} mois. La m√©thodologie IPMVP recommande 12 mois.")
            else:
                st.sidebar.warning(f"‚ö†Ô∏è La p√©riode s√©lectionn√©e est de {months_diff} mois. Pour une analyse standard IPMVP, 12 mois sont recommand√©s.")

# **Variables explicatives (seulement apr√®s importation du fichier)**
var_options = [col for col in df.columns if col not in [date_col, conso_col]] if df is not None else []
selected_vars = st.sidebar.multiselect("üìä Variables explicatives", var_options)

# Type de mod√®le √† utiliser
model_type = st.sidebar.selectbox(
    "üßÆ Type de mod√®le de r√©gression",
    ["Automatique (meilleur mod√®le)", "Lin√©aire", "Ridge", "Lasso", "Polynomiale"],
    index=0,
    help="S√©lectionnez 'Automatique' pour tester tous les types de mod√®les et choisir le meilleur, ou s√©lectionnez un type sp√©cifique"
)

# Param√®tres sp√©cifiques aux mod√®les
if model_type == "Ridge":
    alpha_ridge = st.sidebar.slider(
        "Alpha (r√©gularisation Ridge)", 
        0.01, 10.0, 1.0, 0.01,
        help="Le param√®tre alpha contr√¥le l'intensit√© de la r√©gularisation. Une valeur plus √©lev√©e r√©duit davantage les coefficients pour √©viter le surapprentissage."
    )
elif model_type == "Lasso":
    alpha_lasso = st.sidebar.slider(
        "Alpha (r√©gularisation Lasso)", 
        0.01, 1.0, 0.1, 0.01,
        help="Le param√®tre alpha contr√¥le l'intensit√© de la r√©gularisation. Lasso peut r√©duire certains coefficients √† z√©ro, effectuant ainsi une s√©lection de variables."
    )
elif model_type == "Polynomiale":
    poly_degree = st.sidebar.slider(
        "Degr√© du polyn√¥me", 
        2, 3, 2,
        help="Le degr√© du polyn√¥me d√©termine la complexit√© des relations non lin√©aires. Un degr√© 2 inclut les termes quadratiques (x¬≤), un degr√© 3 inclut √©galement les termes cubiques (x¬≥)."
    )

# Nombre de variables √† tester
max_features = st.sidebar.slider("üî¢ Nombre de variables √† tester", 1, 4, 2)

# Fonction pour cr√©er une info-bulle
def tooltip(text, explanation):
    return f'<span>{text} <span class="tooltip">‚ÑπÔ∏è<span class="tooltiptext">{explanation}</span></span></span>'

# Fonction pour √©valuer la conformit√© IPMVP
def evaluer_conformite(r2, cv_rmse):
    if r2 >= 0.75 and cv_rmse <= 0.15:
        return "Excellente", "good"
    elif r2 >= 0.5 and cv_rmse <= 0.25:
        return "Acceptable", "medium"
    else:
        return "Insuffisante", "bad"

# üìå **Lancement du calcul seulement si le bouton est cliqu√©**
if df is not None and lancer_calcul:
    st.subheader("‚öôÔ∏è Analyse en cours...")
    
    # Convertir la colonne de date si elle ne l'est pas d√©j√†
    if not pd.api.types.is_datetime64_any_dtype(df[date_col]):
        try:
            df[date_col] = pd.to_datetime(df[date_col])
            # Trier le dataframe par date
            df = df.sort_values(by=date_col)
        except:
            st.error("‚ùå La colonne de date n'a pas pu √™tre convertie. Assurez-vous qu'elle contient des dates valides.")
            st.stop()
    
    # Option 1: Recherche automatique de la meilleure p√©riode
    if period_choice == "Rechercher automatiquement la meilleure p√©riode de 12 mois":
        # V√©rifier s'il y a suffisamment de donn√©es (au moins 12 mois)
        date_ranges = []
        min_date = df[date_col].min()
        max_date = df[date_col].max()
        current_date = min_date
        
        while current_date + pd.DateOffset(months=11) <= max_date:
            end_date = current_date + pd.DateOffset(months=11)
            period_name = f"{current_date.strftime('%b %Y')} - {end_date.strftime('%b %Y')}"
            date_ranges.append((period_name, current_date, end_date))
            current_date = current_date + pd.DateOffset(months=1)
        
        if not date_ranges:
            st.error("‚ùå Pas assez de donn√©es pour une analyse sur 12 mois. Assurez-vous d'avoir au moins 12 mois de donn√©es.")
            st.stop()
            
        progress_bar = st.progress(0)
        progress_text = st.empty()
        
        best_period_data = None
        best_period_model = None
        best_period_features = None
        best_period_metrics = None
        best_period_r2 = -1
        
        for idx, (period_name, period_start, period_end) in enumerate(date_ranges):
            progress_text.text(f"Analyse de la p√©riode {period_name} ({idx+1}/{len(date_ranges)})")
            
            # Filtrer les donn√©es pour cette p√©riode
            period_df = df[(df[date_col] >= period_start) & (df[date_col] <= period_end)]
            
            # V√©rifier que les donn√©es sont suffisantes
            if len(period_df) < 10:  # √âviter les p√©riodes avec trop peu de donn√©es
                continue
                
            X = period_df[selected_vars] if selected_vars else pd.DataFrame(index=period_df.index)
            y = period_df[conso_col]
            
            # Nettoyage des donn√©es avant entra√Ænement
            if X.isnull().values.any() or np.isinf(X.values).any():
                continue
                
            if y.isnull().values.any() or np.isinf(y.values).any():
                continue
                
            X = X.apply(pd.to_numeric, errors='coerce').dropna()
            y = pd.to_numeric(y, errors='coerce').dropna()
            
            # Test des combinaisons de variables
            for n in range(1, max_features + 1):
                for combo in combinations(selected_vars, n):
                    X_subset = X[list(combo)]
                    
                    try:
                        # Si mode automatique, tester tous les types de mod√®les
                        if period_choice == "Rechercher automatiquement la meilleure p√©riode de 12 mois" and model_type == "Automatique (meilleur mod√®le)":
                            model_types_to_test = [
                                ("Lin√©aire", LinearRegression(), "R√©gression lin√©aire"),
                                ("Ridge", Ridge(alpha=1.0), f"R√©gression Ridge (Œ±=1.0)"),
                                ("Lasso", Lasso(alpha=0.1), f"R√©gression Lasso (Œ±=0.1)"),
                                ("Polynomiale", Pipeline([
                                    ('poly', PolynomialFeatures(degree=2)),
                                    ('linear', LinearRegression())
                                ]), f"R√©gression polynomiale (degr√© 2)")
                            ]
                            
                            for m_type, m_obj, m_name in model_types_to_test:
                                m_obj.fit(X_subset, y)
                                y_pred = m_obj.predict(X_subset)
                                r2 = r2_score(y, y_pred)
                                
                                if r2 > best_period_r2:
                                    best_period_r2 = r2
                                    best_period_start = period_start
                                    best_period_end = period_end
                                    best_period_name = period_name
                                    best_period_data = period_df
                                    best_period_model = m_obj
                                    best_period_features = list(combo)
                                    
                                    # Calcul des m√©triques
                                    rmse = np.sqrt(mean_squared_error(y, y_pred))
                                    mae = mean_absolute_error(y, y_pred)
                                    cv_rmse = rmse / np.mean(y) if np.mean(y) != 0 else float('inf')
                                    bias = np.mean(y_pred - y) / np.mean(y) * 100
                                    
                                    # R√©cup√©ration des coefficients selon le type de mod√®le
                                    if m_type == "Lin√©aire":
                                        coefs = {feature: coef for feature, coef in zip(combo, m_obj.coef_)}
                                        intercept = m_obj.intercept_
                                    elif m_type in ["Ridge", "Lasso"]:
                                        coefs = {feature: coef for feature, coef in zip(combo, m_obj.coef_)}
                                        intercept = m_obj.intercept_
                                    elif m_type == "Polynomiale":
                                        # Pour le mod√®le polynomial, nous gardons une repr√©sentation simplifi√©e
                                        linear_model = m_obj.named_steps['linear']
                                        poly = m_obj.named_steps['poly']
                                        feature_names = poly.get_feature_names_out(input_features=combo)
                                        coefs = {name: coef for name, coef in zip(feature_names, linear_model.coef_)}
                                        intercept = linear_model.intercept_
                                    
                                    # Statut de conformit√© IPMVP
                                    conformite, classe = evaluer_conformite(r2, cv_rmse)
                                    
                                    # Stockage des m√©triques
                                    best_period_metrics = {
                                        'features': list(combo),
                                        'r2': r2,
                                        'rmse': rmse,
                                        'cv_rmse': cv_rmse,
                                        'mae': mae,
                                        'bias': bias,
                                        'coefficients': coefs,
                                        'intercept': intercept,
                                        'conformite': conformite,
                                        'classe': classe,
                                        'model_type': m_type,
                                        'model_name': m_name
                                    }
                        else:
                            # Cr√©ation du mod√®le selon le type s√©lectionn√©
                            if model_type == "Lin√©aire":
                                model = LinearRegression()
                                model_name = "R√©gression lin√©aire"
                            elif model_type == "Ridge":
                                model = Ridge(alpha=alpha_ridge)
                                model_name = f"R√©gression Ridge (Œ±={alpha_ridge})"
                            elif model_type == "Lasso":
                                model = Lasso(alpha=alpha_lasso)
                                model_name = f"R√©gression Lasso (Œ±={alpha_lasso})"
                            elif model_type == "Polynomiale":
                                model = Pipeline([
                                    ('poly', PolynomialFeatures(degree=poly_degree)),
                                    ('linear', LinearRegression())
                                ])
                                model_name = f"R√©gression polynomiale (degr√© {poly_degree})"
                            
                            model.fit(X_subset, y)
                            
                            # Pr√©dictions selon le type de mod√®le
                            y_pred = model.predict(X_subset)
                            r2 = r2_score(y, y_pred)
                            
                            if r2 > best_period_r2:
                                best_period_r2 = r2
                                best_period_start = period_start
                                best_period_end = period_end
                                best_period_name = period_name
                                best_period_data = period_df
                                best_period_model = model
                                best_period_features = list(combo)
                                
                                # Calcul des m√©triques
                                rmse = np.sqrt(mean_squared_error(y, y_pred))
                                mae = mean_absolute_error(y, y_pred)
                                cv_rmse = rmse / np.mean(y) if np.mean(y) != 0 else float('inf')
                                bias = np.mean(y_pred - y) / np.mean(y) * 100
                                
                                # R√©cup√©ration des coefficients selon le type de mod√®le
                                if model_type == "Lin√©aire":
                                    coefs = {feature: coef for feature, coef in zip(combo, model.coef_)}
                                    intercept = model.intercept_
                                elif model_type in ["Ridge", "Lasso"]:
                                    coefs = {feature: coef for feature, coef in zip(combo, model.coef_)}
                                    intercept = model.intercept_
                                elif model_type == "Polynomiale":
                                    # Pour le mod√®le polynomial, nous gardons une repr√©sentation simplifi√©e
                                    linear_model = model.named_steps['linear']
                                    poly = model.named_steps['poly']
                                    feature_names = poly.get_feature_names_out(input_features=combo)
                                    coefs = {name: coef for name, coef in zip(feature_names, linear_model.coef_)}
                                    intercept = linear_model.intercept_
                                
                                # Statut de conformit√© IPMVP
                                conformite, classe = evaluer_conformite(r2, cv_rmse)
                                
                                # Stockage des m√©triques
                                best_period_metrics = {
                                    'features': list(combo),
                                    'r2': r2,
                                    'rmse': rmse,
                                    'cv_rmse': cv_rmse,
                                    'mae': mae,
                                    'bias': bias,
                                    'coefficients': coefs,
                                    'intercept': intercept,
                                    'conformite': conformite,
                                    'classe': classe,
                                    'model_type': model_type,
                                    'model_name': model_name
                                }
                    except:
                        continue
            
            # Mise √† jour de la barre de progression
            progress_bar.progress((idx + 1) / len(date_ranges))
        
        progress_bar.empty()
        progress_text.empty()
        
        if best_period_data is not None:
            st.success(f"‚úÖ Meilleure p√©riode trouv√©e : {best_period_name}")
            st.info(f"P√©riode : {best_period_start.strftime('%d/%m/%Y')} - {best_period_end.strftime('%d/%m/%Y')}")
            
            # Utiliser les meilleurs r√©sultats trouv√©s
            df_filtered = best_period_data
            best_model = best_period_model
            best_features = best_period_features
            best_metrics = best_period_metrics
            
            # Afficher les d√©tails sur les donn√©es
            st.markdown(f"**üìä Nombre de points de donn√©es :** {len(df_filtered)}")
        else:
            st.error("‚ùå Aucun mod√®le valide n'a √©t√© trouv√© sur les p√©riodes analys√©es.")
            st.stop()
    
    # Option 2: P√©riode sp√©cifique s√©lectionn√©e
    else:
        # Filtrer les donn√©es selon la p√©riode s√©lectionn√©e manuellement
        df_filtered = df[(df[date_col].dt.date >= start_date) & (df[date_col].dt.date <= end_date)]
        
        # Afficher le nombre de points de donn√©es
        st.info(f"Analyse sur la p√©riode du {start_date.strftime('%d/%m/%Y')} au {end_date.strftime('%d/%m/%Y')}")
        st.markdown(f"**üìä Nombre de points de donn√©es :** {len(df_filtered)}")
        
        if len(df_filtered) < 10:
            st.warning("‚ö†Ô∏è Le nombre de points de donn√©es est faible pour une analyse statistique fiable.")
        
        X = df_filtered[selected_vars] if selected_vars else pd.DataFrame(index=df_filtered.index)
        y = df_filtered[conso_col]

        # Nettoyage des donn√©es avant entra√Ænement
        if X.isnull().values.any() or np.isinf(X.values).any():
            st.error("‚ùå Les variables explicatives contiennent des valeurs manquantes ou non num√©riques.")
            st.stop()

        if y.isnull().values.any() or np.isinf(y.values).any():
            st.error("‚ùå La colonne de consommation contient des valeurs manquantes ou non num√©riques.")
            st.stop()

        X = X.apply(pd.to_numeric, errors='coerce').dropna()
        y = pd.to_numeric(y, errors='coerce').dropna()

        best_model = None
        best_r2 = -1
        best_features = []
        best_metrics = {}
        all_models = []

        # üîπ Test des combinaisons de variables (de 1 √† max_features)
        for n in range(1, max_features + 1):
            for combo in combinations(selected_vars, n):
                X_subset = X[list(combo)]
                # Si mode automatique, tester tous les types de mod√®les
                if model_type == "Automatique (meilleur mod√®le)":
                    # Cr√©er une liste pour stocker les r√©sultats des diff√©rents mod√®les
                    temp_models = []
                    
                    # Tester chaque type de mod√®le
                    model_types_to_test = [
                        ("Lin√©aire", LinearRegression(), "R√©gression lin√©aire"),
                        ("Ridge", Ridge(alpha=1.0), f"R√©gression Ridge (Œ±=1.0)"),
                        ("Lasso", Lasso(alpha=0.1), f"R√©gression Lasso (Œ±=0.1)"),
                        ("Polynomiale", Pipeline([
                            ('poly', PolynomialFeatures(degree=2)),
                            ('linear', LinearRegression())
                        ]), f"R√©gression polynomiale (degr√© 2)")
                    ]
                    
                    for m_type, m_obj, m_name in model_types_to_test:
                        m_obj.fit(X_subset, y)
                        y_pred = m_obj.predict(X_subset)
                        
                        # Calcul des m√©triques
                        r2 = r2_score(y, y_pred)
                        rmse = np.sqrt(mean_squared_error(y, y_pred))
                        mae = mean_absolute_error(y, y_pred)
                        cv_rmse = rmse / np.mean(y) if np.mean(y) != 0 else float('inf')
                        bias = np.mean(y_pred - y) / np.mean(y) * 100
                        
                        # R√©cup√©ration des coefficients selon le type de mod√®le
                        if m_type == "Lin√©aire":
                            coefs = {feature: coef for feature, coef in zip(combo, m_obj.coef_)}
                            intercept = m_obj.intercept_
                        elif m_type in ["Ridge", "Lasso"]:
                            coefs = {feature: coef for feature, coef in zip(combo, m_obj.coef_)}
                            intercept = m_obj.intercept_
                        elif m_type == "Polynomiale":
                            # Pour le mod√®le polynomial, nous prenons une repr√©sentation simplifi√©e
                            linear_model = m_obj.named_steps['linear']
                            poly = m_obj.named_steps['poly']
                            feature_names = poly.get_feature_names_out(input_features=combo)
                            coefs = {name: coef for name, coef in zip(feature_names, linear_model.coef_)}
                            intercept = linear_model.intercept_
                        
                        # Statut de conformit√© IPMVP
                        conformite, classe = evaluer_conformite(r2, cv_rmse)
                        
                        # Stockage des r√©sultats du mod√®le
                        model_info = {
                            'features': list(combo),
                            'r2': r2,
                            'rmse': rmse,
                            'cv_rmse': cv_rmse,
                            'mae': mae,
                            'bias': bias,
                            'coefficients': coefs,
                            'intercept': intercept,
                            'conformite': conformite,
                            'classe': classe,
                            'model': m_obj,
                            'model_type': m_type,
                            'model_name': m_name
                        }
                        
                        temp_models.append(model_info)
                        all_models.append(model_info)
                    
                    # Trouver le meilleur mod√®le parmi ceux test√©s
                    best_temp_model = max(temp_models, key=lambda x: x['r2'])
                    
                    if best_temp_model['r2'] > best_r2:
                        best_r2 = best_temp_model['r2']
                        best_model = best_temp_model['model']
                        best_features = best_temp_model['features']
                        best_metrics = best_temp_model
                
                else:
                    # Cr√©ation du mod√®le selon le type s√©lectionn√©
                    if model_type == "Lin√©aire":
                        model = LinearRegression()
                        model_name = "R√©gression lin√©aire"
                    elif model_type == "Ridge":
                        model = Ridge(alpha=alpha_ridge)
                        model_name = f"R√©gression Ridge (Œ±={alpha_ridge})"
                    elif model_type == "Lasso":
                        model = Lasso(alpha=alpha_lasso)
                        model_name = f"R√©gression Lasso (Œ±={alpha_lasso})"
                    elif model_type == "Polynomiale":
                        model = Pipeline([
                            ('poly', PolynomialFeatures(degree=poly_degree)),
                            ('linear', LinearRegression())
                        ])
                        model_name = f"R√©gression polynomiale (degr√© {poly_degree})"
                    
                    model.fit(X_subset, y)
                    
                    # Pr√©dictions selon le type de mod√®le
                    y_pred = model.predict(X_subset)
                    
                    # Calcul des m√©triques
                    r2 = r2_score(y, y_pred)
                    rmse = np.sqrt(mean_squared_error(y, y_pred))
                    mae = mean_absolute_error(y, y_pred)
                    cv_rmse = rmse / np.mean(y) if np.mean(y) != 0 else float('inf')
                    bias = np.mean(y_pred - y) / np.mean(y) * 100
                    
                    # R√©cup√©ration des coefficients selon le type de mod√®le
                    if model_type == "Lin√©aire":
                        coefs = {feature: coef for feature, coef in zip(combo, model.coef_)}
                        intercept = model.intercept_
                    elif model_type in ["Ridge", "Lasso"]:
                        coefs = {feature: coef for feature, coef in zip(combo, model.coef_)}
                        intercept = model.intercept_
                    elif model_type == "Polynomiale":
                        # Pour le mod√®le polynomial, nous gardons une repr√©sentation simplifi√©e
                        linear_model = model.named_steps['linear']
                        poly = model.named_steps['poly']
                        feature_names = poly.get_feature_names_out(input_features=combo)
                        coefs = {name: coef for name, coef in zip(feature_names, linear_model.coef_)}
                        intercept = linear_model.intercept_
                    
                    # Statut de conformit√© IPMVP
                    conformite, classe = evaluer_conformite(r2, cv_rmse)
                    
                    # Stockage du mod√®le
                    model_info = {
                        'features': list(combo),
                        'r2': r2,
                        'rmse': rmse,
                        'cv_rmse': cv_rmse,
                        'mae': mae,
                        'bias': bias,
                        'coefficients': coefs,
                        'intercept': intercept,
                        'conformite': conformite,
                        'classe': classe,
                        'model': model,
                        'model_type': model_type,
                        'model_name': model_name
                    }
                    all_models.append(model_info)

                    if r2 > best_r2:
                        best_r2 = r2
                        best_model = model
                        best_features = list(combo)
                        best_metrics = model_info

        # üîπ Tri des mod√®les par R¬≤ d√©croissant
        all_models.sort(key=lambda x: x['r2'], reverse=True)

    # üîπ R√©sultats du mod√®le s√©lectionn√©
    if best_model:
        st.success("‚úÖ Mod√®le trouv√© avec succ√®s !")
        
        # Cr√©er l'√©quation du mod√®le sous forme de texte
        equation = f"Consommation = {best_metrics['intercept']:.4f}"
        for feature in best_features:
            coef = best_metrics['coefficients'][feature]
            sign = "+" if coef >= 0 else ""
            equation += f" {sign} {coef:.4f} √ó {feature}"
        
        # Afficher les m√©triques dans un tableau
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("üìä R√©sultats du mod√®le")
            st.markdown(f"""
            <div class="metrics-card">
                <h4>Mod√®le s√©lectionn√©: <span class="model-badge">{best_metrics['model_name']}</span></h4>
                <p>Variables utilis√©es: {', '.join(best_features)}</p>
                <p>Conformit√© IPMVP: <span class="conformity-{best_metrics['classe']}">{best_metrics['conformite']}</span></p>
            </div>
            """, unsafe_allow_html=True)
            
            # Cr√©er l'√©quation adapt√©e selon le type de mod√®le
            if best_metrics['model_type'] in ["Lin√©aire", "Ridge", "Lasso"]:
                equation = f"Consommation = {best_metrics['intercept']:.4f}"
                for feature in best_features:
                    coef = best_metrics['coefficients'][feature]
                    sign = "+" if coef >= 0 else ""
                    equation += f" {sign} {coef:.4f} √ó {feature}"
            elif best_metrics['model_type'] == "Polynomiale":
                equation = f"Consommation = {best_metrics['intercept']:.4f}"
                for feature_name, coef in best_metrics['coefficients'].items():
                    sign = "+" if coef >= 0 else ""
                    equation += f" {sign} {coef:.4f} √ó {feature_name}"
            
            st.markdown(f"""
            <div class="equation-box">
                <h4>√âquation d'ajustement:</h4>
                <p>{equation}</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            # Tableau des m√©triques avec info-bulles
            st.markdown(f"""
            <table style="width:100%">
                <tr>
                    <th>M√©trique</th>
                    <th>Valeur</th>
                </tr>
                <tr>
                    <td>{tooltip("R¬≤", "Coefficient de d√©termination : mesure la proportion de variance de la variable d√©pendante qui est pr√©dite √† partir des variables ind√©pendantes. Plus cette valeur est proche de 1, meilleur est l'ajustement du mod√®le aux donn√©es.")}</td>
                    <td>{best_metrics['r2']:.4f}</td>
                </tr>
                <tr>
                    <td>{tooltip("RMSE", "Root Mean Square Error (Erreur quadratique moyenne) : mesure l'√©cart-type des r√©sidus (erreurs de pr√©diction). Exprim√©e dans la m√™me unit√© que la variable d√©pendante.")}</td>
                    <td>{best_metrics['rmse']:.4f}</td>
                </tr>
                <tr>
                    <td>{tooltip("CV(RMSE)", "Coefficient de Variation du RMSE : exprime le RMSE en pourcentage de la moyenne observ√©e, permettant de comparer la pr√©cision entre diff√©rents mod√®les ind√©pendamment de l'√©chelle.")}</td>
                    <td>{best_metrics['cv_rmse']:.4f}</td>
                </tr>
                <tr>
                    <td>{tooltip("MAE", "Mean Absolute Error (Erreur absolue moyenne) : moyenne des valeurs absolues des erreurs. Moins sensible aux valeurs extr√™mes que le RMSE.")}</td>
                    <td>{best_metrics['mae']:.4f}</td>
                </tr>
                <tr>
                    <td>{tooltip("Biais (%)", "Repr√©sente l'erreur syst√©matique du mod√®le en pourcentage. Un biais positif indique une surestimation, un biais n√©gatif une sous-estimation.")}</td>
                    <td>{best_metrics['bias']:.2f}</td>
                </tr>
            </table>
            """, unsafe_allow_html=True)

        # üîπ Graphique de consommation
        st.subheader("üìà Visualisation des r√©sultats")
        
        # Pr√©dictions du mod√®le
        X_best = df_filtered[best_features]
        y_pred = best_model.predict(X_best)
        
        # Configuration du style des graphiques pour correspondre au th√®me
        plt.style.use('seaborn-v0_8-whitegrid')
        plt.rcParams['axes.facecolor'] = '#F5F5F5'
        plt.rcParams['figure.facecolor'] = '#E7DDD9'
        plt.rcParams['axes.edgecolor'] = '#00485F'
        plt.rcParams['axes.labelcolor'] = '#00485F'
        plt.rcParams['axes.titlecolor'] = '#00485F'
        plt.rcParams['xtick.color'] = '#0C1D2D'
        plt.rcParams['ytick.color'] = '#0C1D2D'
        plt.rcParams['grid.color'] = '#00485F'
        plt.rcParams['grid.alpha'] = 0.1
        
        # Graphique de comparaison
        fig, ax = plt.subplots(figsize=(12, 6))
        ax.bar(range(len(y)), y, color="#6DBABC", alpha=0.8, label="Consommation mesur√©e")
        ax.plot(range(len(y)), y_pred, color="#96B91D", marker='o', linewidth=2, markersize=4, label="Consommation ajust√©e", zorder=10)
        ax.set_title("Comparaison Consommation Mesur√©e vs Ajust√©e", fontweight='bold', fontsize=14)
        ax.set_xlabel("Observations", fontweight='bold')
        ax.set_ylabel("Consommation", fontweight='bold')
        ax.legend(frameon=True, facecolor="#E7DDD9", edgecolor="#00485F")
        ax.grid(True, linestyle='--', alpha=0.2)
        # Annotation du R¬≤
        ax.annotate(f"R¬≤ = {best_metrics['r2']:.4f}", xy=(0.02, 0.95), xycoords='axes fraction',
                    fontsize=12, fontweight='bold', color='#00485F',
                    bbox=dict(boxstyle="round,pad=0.3", facecolor="#E7DDD9", edgecolor="#00485F", alpha=0.8))
        st.pyplot(fig)
        
        # Cr√©ation d'une mise en page en colonnes pour les deux derniers graphiques
        col1, col2 = st.columns(2)
        
        with col1:
            # Graphique de dispersion (measured vs predicted)
            fig2, ax2 = plt.subplots(figsize=(8, 7))
            scatter = ax2.scatter(y, y_pred, color="#6DBABC", alpha=0.8, s=50, edgecolor='#00485F')
            
            # Ligne de r√©f√©rence y=x
            min_val = min(min(y), min(y_pred))
            max_val = max(max(y), max(y_pred))
            ax2.plot([min_val, max_val], [min_val, max_val], '--', color='#00485F', linewidth=1.5, label="R√©f√©rence y=x")
            
            ax2.set_title("Consommation Mesur√©e vs Pr√©dite", fontweight='bold', fontsize=14)
            ax2.set_xlabel("Consommation Mesur√©e", fontweight='bold')
            ax2.set_ylabel("Consommation Pr√©dite", fontweight='bold')
            ax2.legend(frameon=True, facecolor="#E7DDD9", edgecolor="#00485F")
            ax2.grid(True, linestyle='--', alpha=0.2)
            # Annotation du CV(RMSE)
            ax2.annotate(f"CV(RMSE) = {best_metrics['cv_rmse']:.4f}", xy=(0.02, 0.95), xycoords='axes fraction',
                        fontsize=12, fontweight='bold', color='#00485F',
                        bbox=dict(boxstyle="round,pad=0.3", facecolor="#E7DDD9", edgecolor="#00485F", alpha=0.8))
            st.pyplot(fig2)
        
        with col2:
            # Affichage des r√©sidus
            residus = y - y_pred
            
            fig3, ax3 = plt.subplots(figsize=(8, 7))
            ax3.scatter(range(len(residus)), residus, color="#96B91D", alpha=0.8, s=50, edgecolor='#00485F')
            ax3.axhline(y=0, color='#00485F', linestyle='-', alpha=0.5, linewidth=1.5)
            ax3.set_title("Analyse des R√©sidus", fontweight='bold', fontsize=14)
            ax3.set_xlabel("Observations", fontweight='bold')
            ax3.set_ylabel("R√©sidus", fontweight='bold')
            ax3.grid(True, linestyle='--', alpha=0.2)
            
            # Annotation du biais
            ax3.annotate(f"Biais = {best_metrics['bias']:.2f}%", xy=(0.02, 0.95), xycoords='axes fraction',
                        fontsize=12, fontweight='bold', color='#00485F',
                        bbox=dict(boxstyle="round,pad=0.3", facecolor="#E7DDD9", edgecolor="#00485F", alpha=0.8))
            st.pyplot(fig3)
            
        # Ajout d'un expander pour expliquer les diff√©rents mod√®les de r√©gression
        with st.expander("üìö Interpr√©tation des diff√©rents mod√®les de r√©gression"):
            st.markdown("""
            ### Types de mod√®les de r√©gression
            
            **R√©gression lin√©aire multiple**
            - Mod√®le le plus courant pour l'IPMVP
            - √âtablit une relation lin√©aire : Y = a‚ÇÄ + a‚ÇÅX‚ÇÅ + a‚ÇÇX‚ÇÇ + ... + a‚ÇôX‚Çô
            - Forces : Simple √† interpr√©ter, rapide √† calculer
            - Limites : Ne peut capturer que des relations lin√©aires
            - Statut IPMVP : Explicitement mentionn√© et recommand√© dans le protocole
            
            **R√©gression Ridge**
            - Ajoute une p√©nalit√© √† la somme des carr√©s des coefficients
            - Formule : Y = a‚ÇÄ + a‚ÇÅX‚ÇÅ + a‚ÇÇX‚ÇÇ + ... + a‚ÇôX‚Çô, avec minimisation de (r√©sidus¬≤ + Œ± √ó somme des coefficients¬≤)
            - Forces : G√®re mieux les variables corr√©l√©es, r√©duit le risque de surapprentissage
            - Limites : Tous les coefficients sont r√©duits mais aucun n'est √©limin√©
            - Statut IPMVP : Acceptable si les crit√®res statistiques sont respect√©s et si le mod√®le reste documentable
            
            **R√©gression Lasso**
            - Ajoute une p√©nalit√© √† la somme des valeurs absolues des coefficients
            - Formule : Y = a‚ÇÄ + a‚ÇÅX‚ÇÅ + a‚ÇÇX‚ÇÇ + ... + a‚ÇôX‚Çô, avec minimisation de (r√©sidus¬≤ + Œ± √ó somme des |coefficients|)
            - Forces : Peut √©liminer compl√®tement des variables non pertinentes (coefficients = 0)
            - Limites : Peut √™tre instable si les variables sont tr√®s corr√©l√©es
            - Statut IPMVP : Acceptable et peut m√™me √™tre pr√©f√©rable pour des mod√®les plus simples et robustes
            
            **R√©gression polynomiale**
            - Introduit des termes non lin√©aires (carr√©s, cubes, produits crois√©s)
            - Formule : Y = a‚ÇÄ + a‚ÇÅX‚ÇÅ + a‚ÇÇX‚ÇÅ¬≤ + a‚ÇÉX‚ÇÇ + a‚ÇÑX‚ÇÇ¬≤ + a‚ÇÖX‚ÇÅX‚ÇÇ + ...
            - Forces : Peut capturer des relations non lin√©aires
            - Limites : Risque √©lev√© de surapprentissage, interpr√©tation plus complexe
            - Statut IPMVP : Acceptable si les relations physiques sont plausibles et document√©es
            """)
            
            st.info("""
            **Note sur la conformit√© IPMVP**
            
            Le protocole IPMVP (Option C) n'impose pas une m√©thode statistique sp√©cifique, mais plut√¥t des crit√®res de qualit√©:
            
            1. Le mod√®le doit avoir un R¬≤ ‚â• 0.75 et un CV(RMSE) ‚â§ 15%
            2. Le mod√®le doit √™tre documentable et transparent
            3. Les variables explicatives doivent avoir une relation plausible avec la consommation
            4. L'erreur-type des coefficients doit √™tre √©valu√©e
            
            Les m√©thodes avanc√©es (Ridge, Lasso, polynomiale) sont acceptables et peuvent m√™me produire des mod√®les plus robustes dans certaines situations, tant qu'elles respectent ces crit√®res.
            """)

        
        # üîπ Tableau des r√©sultats pour tous les mod√®les test√©s
        st.subheader("üìã Classement des mod√®les test√©s")
        models_summary = []
        
        for i, model in enumerate(all_models[:10]):  # Afficher les 10 meilleurs mod√®les
            models_summary.append({
                "Rang": i+1,
                "Type": model['model_name'],
                "Variables": ", ".join(model['features']),
                "R¬≤": f"{model['r2']:.4f}",
                "CV(RMSE)": f"{model['cv_rmse']:.4f}",
                "Biais (%)": f"{model['bias']:.2f}",
                "Conformit√©": model['conformite']
            })
        
        st.table(pd.DataFrame(models_summary))
        
    else:
        st.error("‚ö†Ô∏è Aucun mod√®le valide n'a √©t√© trouv√©.")

st.sidebar.markdown("---")

# Ajout d'informations sur la m√©thodologie IPMVP avec infobulles
st.sidebar.markdown(f"""
### üìò M√©thodologie IPMVP
La m√©thodologie IPMVP √©value la qualit√© d'un mod√®le de r√©gression selon ces crit√®res :

- {tooltip("R¬≤ ‚â• 0.75", "Le coefficient de d√©termination R¬≤ mesure la proportion de la variance expliqu√©e par le mod√®le. Une valeur de 0.75 signifie que 75% de la variabilit√© des donn√©es est expliqu√©e par le mod√®le.")} : Excellente corr√©lation
- {tooltip("CV(RMSE) ‚â§ 15%", "Le coefficient de variation de l'erreur quadratique moyenne repr√©sente la dispersion relative des r√©sidus. Il est calcul√© en divisant le RMSE par la moyenne des observations.")} : Excellente pr√©cision
- {tooltip("Biais < 5%", "Le biais repr√©sente l'erreur syst√©matique du mod√®le. Un biais faible indique que le mod√®le ne surestime ni ne sous-estime syst√©matiquement les valeurs.")} : Ajustement √©quilibr√©
""", unsafe_allow_html=True)

# Information sur les types de r√©gression
st.sidebar.markdown(f"""
### üìä Types de mod√®les
- {tooltip("R√©gression lin√©aire", "Mod√®le standard qui √©tablit une relation lin√©aire entre les variables ind√©pendantes et la consommation. C'est le mod√®le le plus couramment utilis√© et explicitement mentionn√© dans l'IPMVP.")}
- {tooltip("R√©gression Ridge", "Technique de r√©gularisation qui r√©duit le risque de surapprentissage en p√©nalisant les coefficients √©lev√©s. Conforme √† l'IPMVP tant que les crit√®res de qualit√© statistique (R¬≤, CV) sont respect√©s et que le mod√®le reste documentable.")}
- {tooltip("R√©gression Lasso", "M√©thode qui peut r√©duire certains coefficients √† z√©ro, effectuant ainsi une s√©lection de variables. Conforme √† l'IPMVP car elle simplifie le mod√®le tout en maintenant sa pr√©cision statistique.")}
- {tooltip("R√©gression polynomiale", "Permet de mod√©liser des relations non lin√©aires. L'IPMVP accepte les mod√®les non lin√©aires si les relations physiques sont plausibles et si les crit√®res statistiques sont respect√©s.")}
""", unsafe_allow_html=True)

# Information sur la conformit√© IPMVP des mod√®les avanc√©s
st.sidebar.markdown(f"""
### ‚úÖ Conformit√© IPMVP
{tooltip("Mod√®les avanc√©s et IPMVP", "Le protocole IPMVP ne prescrit pas de m√©thode statistique sp√©cifique, mais √©tablit des crit√®res de qualit√© statistique (R¬≤ et CV(RMSE)). Les m√©thodes avanc√©es comme Ridge, Lasso ou polynomiale sont acceptables si elles respectent ces crit√®res et si le mod√®le reste transparent et documentable.")}

Les mod√®les sont √©valu√©s selon les crit√®res IPMVP :
- R¬≤ ‚â• 0.75 : Excellente corr√©lation
- CV(RMSE) ‚â§ 15% : Excellente pr√©cision
""", unsafe_allow_html=True)

# Pied de page am√©lior√©
st.markdown("---")
st.markdown("""
<div class="footer-credit">
    <p>D√©velopp√© avec ‚ù§Ô∏è par <strong>Efficacit√© Energ√©tique, Carbone & RSE team</strong> ¬© 2025</p>
    <p>Outil d'analyse et de mod√©lisation √©nerg√©tique conforme IPMVP</p>
</div>
""", unsafe_allow_html=True)
